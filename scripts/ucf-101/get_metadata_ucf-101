#!/usr/bin/env python3

from PIL import Image

import argparse
import csv
import json
import os
import multiprocessing as mp
import numpy as np

def get_video_stats(inp):
    data_root, video_path, data_labels, labels_num2str = inp

    pathgen = lambda x : os.path.join(args.data_root, video_path, x)
    frames = sorted( os.listdir(pathgen('')) )

    assert len(frames) > 0, video_path
    image = Image.open(pathgen(frames[0]))
        
    metadata = {
        'num_frames' : len(frames),
        'frame_width' : image.size[0],
        'frame_height' : image.size[1],
        'label_num' : data_labels[video_path],
        'label_str' : labels_num2str[ data_labels[video_path] ]
    }    
    return metadata

def main(args):

    with open(args.label_file, 'r') as csvfile:
        reader = csv.reader(csvfile, delimiter=' ')
        labels_num2str = [ item[1] for item in reader ]
        labels_str2num =  { label : idx  for idx,label in zip(range(len(labels_num2str)), labels_num2str) }
        
    with open(args.data_file, 'r') as csvfile:
        reader = csv.reader(csvfile, delimiter=' ')
        data_labels = { item[0].split('.')[0] : labels_str2num[item[0].split('/')[0]] for item in reader }; 
        data_video_paths = list(data_labels.keys())

    pool = mp.Pool(processes=mp.cpu_count())
    jobs = [ (args.data_root, video_path, data_labels, labels_num2str) for video_path in data_video_paths ] 
    
    video_stats = pool.map(get_video_stats, jobs)

    metadata = {}
    metadata['label_file'] = os.path.abspath(args.label_file)
    metadata['data_file'] = os.path.abspath(args.data_file)
    metadata['label_num2str'] = labels_num2str
    metadata['videos'] = video_stats

    print( json.dumps(metadata, indent=4, sort_keys=True) )    

if(__name__ == '__main__'):
    parser = argparse.ArgumentParser(description='collect metadata on videos the UCF-101 dataset and output to STDOUT in json format')
    
    parser.add_argument('label_file', type=str, nargs=None,
                        help='labels file')

    parser.add_argument('data_file', type=str, nargs=None,
                        help='train/validation file')
    
    parser.add_argument('data_root', type=str, nargs=None,
                        help='the root directory of the data set')

    args = parser.parse_args()
    main(args)
