Things we know:
- you cannot train directly on the something-something, ucf-101, or hmdb-51 datasets (will overfit)
- you CAN train directly on imagenet and jester datasets

Things to do:

- rerun models with something-something dataset
[] model24 ("short LSTM" model where the outputs of fb iterations aren't combined, separate LSTM for each sequence.)
[] model26 ("long LSTM" model where the outputs of the 3 fb iterations are concatenated then fed into an LSTM.)
[] model28 ("long LSTM" model where the frist fb iteration is fed into the LSTM three time.)

- new model architectures
[] simple convRNN in spatial iterations with convLSTM in time
